{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\s113277\\.conda\\envs\\base2\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#Imports & db connection setup\n",
    "from modules.preamble import *\n",
    "from modules.event_data_conversion import get_time_between_events, events_to_rt_pred\n",
    "\n",
    "#Enter information to access your PostgreSQL MIMIC database from Python\n",
    "con = psycopg2.connect(dbname='mimic', user='postgres', password='postgres', port=5433) #Your credentials for the database connector\n",
    "query_schema = 'set search_path to mimiciii;' #Your search path to the MIMIC-III schema\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data\n",
    "Including some preliminary cleaning & merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load datasets from the \"Event Tables Filtering\" notebook\n",
    "df_bm = pd.read_hdf(os.path.join(data_base_path, \"cleaned_BM_events.hdf\"));\n",
    "df_lt = pd.read_hdf(os.path.join(data_base_path, \"cleaned_LT_events.hdf\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the at3 variable because it was only measured 4 times in total\n",
    "df_lt = df_lt[~(df_lt['variable']=='at3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all events with valuenum = NaN. They cannot be used anyway\n",
    "df_bm = df_bm[~df_bm['valuenum'].isnull()]\n",
    "df_lt = df_lt[~df_lt['valuenum'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenated into a single dataframe\n",
    "df = pd.concat([df_bm, df_lt]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Events-to-modeling format\n",
    "Use the full forward imputation per patient, as we found this to be the most effective imputation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling variable 0: arterial base excess\n",
      "Filling variable 1: arterial pco2\n",
      "Filling variable 2: arterial ph\n",
      "Filling variable 3: arterial po2\n",
      "Filling variable 4: bicarbonate\n",
      "Filling variable 5: bilirubin\n",
      "Filling variable 6: calcium\n",
      "Filling variable 7: creatinine\n",
      "Filling variable 8: crp\n",
      "Filling variable 9: cvp\n",
      "Filling variable 10: diastolic blood pressure\n",
      "Filling variable 11: fio2\n",
      "Filling variable 12: glucose\n",
      "Filling variable 13: got(asat)\n",
      "Filling variable 14: gpt(alat)\n",
      "Filling variable 15: heart rate\n",
      "Filling variable 16: hematocrit\n",
      "Filling variable 17: platelets\n",
      "Filling variable 18: potassium\n",
      "Filling variable 19: ptt\n",
      "Filling variable 20: sodium\n",
      "Filling variable 21: spo2\n",
      "Filling variable 22: systolic blood pressure\n",
      "Filling variable 23: temperature\n",
      "Filling variable 24: urea\n",
      "Filling variable 25: white blood cells\n"
     ]
    }
   ],
   "source": [
    "#First dataset for modeling\n",
    "df_mod1 = events_to_rt_pred(df = df[['subject_id', 'charttime', 'variable', 'valuenum']],\n",
    "                            max_cft = pd.Timedelta('200y'),\n",
    "                            verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the target label again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_TOD(database_connection):\n",
    "    \"\"\"\n",
    "    Extracts table with the times of death of the septic shock patients. \n",
    "    Returns the result as a dataframe.\n",
    "    \n",
    "    inputs\n",
    "    -----\n",
    "    database_connection: database connection to the MIMIC-III PostgreSQL database.\n",
    "    \"\"\"\n",
    "    \n",
    "    qry = query_schema + \"\"\" \n",
    "        WITH ss_patients AS (\n",
    "            SELECT *\n",
    "            FROM explicit_sepsis\n",
    "            WHERE septic_shock=1\n",
    "        )\n",
    "        \n",
    "        SELECT\n",
    "            a.subject_id, max(a.deathtime) as deathtime\n",
    "        FROM\n",
    "            admissions AS a \n",
    "            INNER JOIN\n",
    "                ss_patients AS ssp \n",
    "                    ON \n",
    "                        a.subject_id = ssp.subject_id \n",
    "                        AND\n",
    "                        a.hadm_id = ssp.hadm_id\n",
    "        GROUP BY a.subject_id\n",
    "        ORDER BY a.subject_id\n",
    "        \n",
    "    \"\"\"\n",
    "    df = pd.read_sql(qry, database_connection, parse_dates = 'deathtime')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tod = extract_TOD(con)\n",
    "\n",
    "df_mod1 = df_mod1.merge(df_tod, on='subject_id', how='left')\n",
    "df_mod1['time to death'] = df_mod1['deathtime'] - df_mod1['charttime']\n",
    "\n",
    "    #Add the label we are interested in: mortality within 72h\n",
    "df_mod1['y'] = (df_mod1['time to death'] <= pd.Timedelta('72 hours')).astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patient/case based split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly put split train-val-test 70-%-15%-15% based on patients\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state= 10 #Trial & error with random state such that we approximately have 70%-15%-15%\n",
    "\n",
    "#Select all subjects and whether they have y=1 eventually\n",
    "all_subjects = df_mod1['subject_id'].unique()\n",
    "all_subj_labels = df_mod1.groupby('subject_id')['y'].max().sort_index().values\n",
    "\n",
    "#Make a split among subjects, stratified on the target label\n",
    "#First set 30% aside, and then split that 30% 50-50 to get the desired 70%-15%-15%\n",
    "train_subj, test_subj, train_subj_labels, test_subj_labels = train_test_split(\n",
    "    all_subjects, \n",
    "    all_subj_labels,\n",
    "    test_size=0.3,\n",
    "    random_state=random_state,\n",
    "    stratify=all_subj_labels)\n",
    "\n",
    "val_subj, test_subj = train_test_split(\n",
    "    test_subj,\n",
    "    test_size=0.5,\n",
    "    random_state=random_state,\n",
    "    stratify=test_subj_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patients in train, val test sets: 1691 362 363\n",
      "Observations in train, val test sets: 688457 117419 118967\n",
      "% of total observations in train, val, test sets 74.44041853590285 12.696100851712128 12.86348061238502 \n",
      "\n",
      "Fraction y=1 in train, val, test sets: 0.0991783074324177 0.10306679498207275 0.09909470693553675\n"
     ]
    }
   ],
   "source": [
    "#Split the instances for modeling based on the subjects\n",
    "df_train, df_val, df_test = [df_mod1[df_mod1['subject_id'].isin(train_subj)],\n",
    "                             df_mod1[df_mod1['subject_id'].isin(val_subj)], \n",
    "                             df_mod1[df_mod1['subject_id'].isin(test_subj)]]\n",
    "\n",
    "#Check if split conforms to requirements\n",
    "print(\"Patients in train, val test sets:\", len(train_subj), len(val_subj), len(test_subj))\n",
    "print(\"Observations in train, val test sets:\", len(df_train), len(df_val), len(df_test))\n",
    "print(\"% of total observations in train, val, test sets\",\n",
    "      len(df_train)/len(df_mod1)*100,\n",
    "      len(df_val)/len(df_mod1)*100,\n",
    "      len(df_test)/len(df_mod1)*100, \"\\n\")\n",
    "print('Fraction y=1 in train, val, test sets:', df_train['y'].mean(), df_val['y'].mean(), df_test['y'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-sort all datasets based on instances & time\n",
    "df_train = df_train.sort_values(['subject_id', 'charttime']).reset_index(drop=True)\n",
    "df_val = df_val.sort_values(['subject_id', 'charttime']).reset_index(drop=True)\n",
    "df_test = df_test.sort_values(['subject_id', 'charttime']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation & normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((688457, 26), (117419, 26), (118967, 26), (688457,), (117419,), (118967,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Storing train-val-test features & labels in numpy format\n",
    "feat_colnames = df_train.columns[2:-3]\n",
    "X_train, X_val, X_test = df_train[feat_colnames].values, \\\n",
    "    df_val[feat_colnames].values, \\\n",
    "    df_test[feat_colnames].values\n",
    "y_train, y_val, y_test = df_train['y'].values, df_val['y'].values, df_test['y'].values\n",
    "\n",
    "#Checking shapes\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Imputation\n",
    "si = SimpleImputer(strategy='mean')\n",
    "X_train = si.fit_transform(X_train)\n",
    "X_val = si.transform(X_val)\n",
    "X_test = si.transform(X_test)\n",
    "\n",
    "#Scaling / normalization\n",
    "ss = StandardScaler()\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_val = ss.transform(X_val)\n",
    "X_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store means & stds used for imputation to recover original scale later\n",
    "means = ss.mean_\n",
    "stds = np.sqrt(ss.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "      <td>6.884570e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.116436e-13</td>\n",
       "      <td>4.160303e-14</td>\n",
       "      <td>-1.055183e-14</td>\n",
       "      <td>3.791913e-14</td>\n",
       "      <td>1.370912e-13</td>\n",
       "      <td>1.698510e-14</td>\n",
       "      <td>3.876798e-14</td>\n",
       "      <td>6.460419e-14</td>\n",
       "      <td>6.156123e-14</td>\n",
       "      <td>2.066529e-15</td>\n",
       "      <td>4.050591e-15</td>\n",
       "      <td>-4.985240e-14</td>\n",
       "      <td>-3.061817e-14</td>\n",
       "      <td>-7.972327e-15</td>\n",
       "      <td>1.499832e-15</td>\n",
       "      <td>1.589692e-14</td>\n",
       "      <td>-1.646681e-15</td>\n",
       "      <td>3.944007e-14</td>\n",
       "      <td>-1.768761e-14</td>\n",
       "      <td>-1.421181e-14</td>\n",
       "      <td>4.660061e-14</td>\n",
       "      <td>-5.213436e-13</td>\n",
       "      <td>-1.205046e-14</td>\n",
       "      <td>-2.197143e-14</td>\n",
       "      <td>-3.190386e-14</td>\n",
       "      <td>4.919475e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>1.000001e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-8.429132e+00</td>\n",
       "      <td>-2.528253e+00</td>\n",
       "      <td>-1.311051e+01</td>\n",
       "      <td>-1.987826e+00</td>\n",
       "      <td>-3.027848e+00</td>\n",
       "      <td>-4.587794e-01</td>\n",
       "      <td>-7.603983e+00</td>\n",
       "      <td>-1.213542e+00</td>\n",
       "      <td>-4.708129e+00</td>\n",
       "      <td>-3.578643e+00</td>\n",
       "      <td>-2.988981e+00</td>\n",
       "      <td>-3.075588e+00</td>\n",
       "      <td>-2.281377e+00</td>\n",
       "      <td>-1.906584e-01</td>\n",
       "      <td>-2.757858e-01</td>\n",
       "      <td>-4.923800e+00</td>\n",
       "      <td>-6.231042e+00</td>\n",
       "      <td>-1.396901e+00</td>\n",
       "      <td>-4.507422e+00</td>\n",
       "      <td>-1.212660e+00</td>\n",
       "      <td>-7.298593e+00</td>\n",
       "      <td>-1.561772e+01</td>\n",
       "      <td>-4.557371e+00</td>\n",
       "      <td>-7.979223e+00</td>\n",
       "      <td>-1.266837e+00</td>\n",
       "      <td>-1.427581e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.655641e-01</td>\n",
       "      <td>-5.814442e-01</td>\n",
       "      <td>-5.758826e-01</td>\n",
       "      <td>-5.532557e-01</td>\n",
       "      <td>-6.628083e-01</td>\n",
       "      <td>-3.835310e-01</td>\n",
       "      <td>-6.402645e-01</td>\n",
       "      <td>-6.705058e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.573284e-16</td>\n",
       "      <td>-6.704212e-01</td>\n",
       "      <td>-6.315674e-01</td>\n",
       "      <td>-5.763983e-01</td>\n",
       "      <td>-1.615546e-01</td>\n",
       "      <td>-2.206083e-01</td>\n",
       "      <td>-7.222200e-01</td>\n",
       "      <td>-6.744245e-01</td>\n",
       "      <td>-7.776170e-01</td>\n",
       "      <td>-6.856271e-01</td>\n",
       "      <td>-5.680196e-01</td>\n",
       "      <td>-6.669183e-01</td>\n",
       "      <td>-3.647201e-01</td>\n",
       "      <td>-6.957136e-01</td>\n",
       "      <td>-5.647793e-01</td>\n",
       "      <td>-6.792776e-01</td>\n",
       "      <td>-6.114259e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.528693e-03</td>\n",
       "      <td>-9.474196e-02</td>\n",
       "      <td>6.363918e-02</td>\n",
       "      <td>-1.073758e-01</td>\n",
       "      <td>-3.213100e-02</td>\n",
       "      <td>-3.270947e-01</td>\n",
       "      <td>-5.011879e-02</td>\n",
       "      <td>-3.688190e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.573284e-16</td>\n",
       "      <td>-9.078128e-02</td>\n",
       "      <td>-2.056221e-02</td>\n",
       "      <td>-1.762504e-01</td>\n",
       "      <td>-1.373014e-01</td>\n",
       "      <td>-1.826737e-01</td>\n",
       "      <td>-3.082076e-02</td>\n",
       "      <td>-9.074618e-02</td>\n",
       "      <td>-1.833547e-01</td>\n",
       "      <td>-1.871320e-01</td>\n",
       "      <td>-3.182942e-01</td>\n",
       "      <td>-8.177058e-02</td>\n",
       "      <td>1.984675e-01</td>\n",
       "      <td>-1.056716e-01</td>\n",
       "      <td>-2.554492e-02</td>\n",
       "      <td>-3.155505e-01</td>\n",
       "      <td>-2.089383e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.158483e-01</td>\n",
       "      <td>3.108433e-01</td>\n",
       "      <td>7.031610e-01</td>\n",
       "      <td>3.385041e-01</td>\n",
       "      <td>5.985463e-01</td>\n",
       "      <td>-6.372540e-02</td>\n",
       "      <td>5.400269e-01</td>\n",
       "      <td>4.155666e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.573284e-16</td>\n",
       "      <td>5.661440e-01</td>\n",
       "      <td>4.341453e-16</td>\n",
       "      <td>3.456817e-01</td>\n",
       "      <td>-7.424316e-02</td>\n",
       "      <td>-6.542138e-02</td>\n",
       "      <td>6.924892e-01</td>\n",
       "      <td>5.162793e-01</td>\n",
       "      <td>5.547818e-01</td>\n",
       "      <td>6.436931e-01</td>\n",
       "      <td>1.485450e-01</td>\n",
       "      <td>6.984264e-01</td>\n",
       "      <td>5.739258e-01</td>\n",
       "      <td>6.074958e-01</td>\n",
       "      <td>5.136853e-01</td>\n",
       "      <td>3.279667e-01</td>\n",
       "      <td>3.947932e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.241498e+00</td>\n",
       "      <td>9.233718e+00</td>\n",
       "      <td>4.796101e+00</td>\n",
       "      <td>1.022541e+01</td>\n",
       "      <td>4.067271e+00</td>\n",
       "      <td>1.500476e+01</td>\n",
       "      <td>2.261148e+01</td>\n",
       "      <td>1.206068e+01</td>\n",
       "      <td>4.171971e+00</td>\n",
       "      <td>7.088789e+00</td>\n",
       "      <td>7.058111e+00</td>\n",
       "      <td>3.034464e+00</td>\n",
       "      <td>5.967196e+01</td>\n",
       "      <td>3.833469e+01</td>\n",
       "      <td>2.870967e+01</td>\n",
       "      <td>6.510879e+00</td>\n",
       "      <td>7.520419e+00</td>\n",
       "      <td>7.726590e+00</td>\n",
       "      <td>1.152750e+01</td>\n",
       "      <td>5.760443e+00</td>\n",
       "      <td>8.305347e+00</td>\n",
       "      <td>8.085873e-01</td>\n",
       "      <td>4.077391e+00</td>\n",
       "      <td>6.849665e+00</td>\n",
       "      <td>4.636734e+00</td>\n",
       "      <td>2.159248e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05   \n",
       "mean   2.116436e-13  4.160303e-14 -1.055183e-14  3.791913e-14  1.370912e-13   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -8.429132e+00 -2.528253e+00 -1.311051e+01 -1.987826e+00 -3.027848e+00   \n",
       "25%   -6.655641e-01 -5.814442e-01 -5.758826e-01 -5.532557e-01 -6.628083e-01   \n",
       "50%    9.528693e-03 -9.474196e-02  6.363918e-02 -1.073758e-01 -3.213100e-02   \n",
       "75%    5.158483e-01  3.108433e-01  7.031610e-01  3.385041e-01  5.985463e-01   \n",
       "max    5.241498e+00  9.233718e+00  4.796101e+00  1.022541e+01  4.067271e+00   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05   \n",
       "mean   1.698510e-14  3.876798e-14  6.460419e-14  6.156123e-14  2.066529e-15   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -4.587794e-01 -7.603983e+00 -1.213542e+00 -4.708129e+00 -3.578643e+00   \n",
       "25%   -3.835310e-01 -6.402645e-01 -6.705058e-01  0.000000e+00  5.573284e-16   \n",
       "50%   -3.270947e-01 -5.011879e-02 -3.688190e-01  0.000000e+00  5.573284e-16   \n",
       "75%   -6.372540e-02  5.400269e-01  4.155666e-01  0.000000e+00  5.573284e-16   \n",
       "max    1.500476e+01  2.261148e+01  1.206068e+01  4.171971e+00  7.088789e+00   \n",
       "\n",
       "                 10            11            12            13            14  \\\n",
       "count  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05   \n",
       "mean   4.050591e-15 -4.985240e-14 -3.061817e-14 -7.972327e-15  1.499832e-15   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -2.988981e+00 -3.075588e+00 -2.281377e+00 -1.906584e-01 -2.757858e-01   \n",
       "25%   -6.704212e-01 -6.315674e-01 -5.763983e-01 -1.615546e-01 -2.206083e-01   \n",
       "50%   -9.078128e-02 -2.056221e-02 -1.762504e-01 -1.373014e-01 -1.826737e-01   \n",
       "75%    5.661440e-01  4.341453e-16  3.456817e-01 -7.424316e-02 -6.542138e-02   \n",
       "max    7.058111e+00  3.034464e+00  5.967196e+01  3.833469e+01  2.870967e+01   \n",
       "\n",
       "                 15            16            17            18            19  \\\n",
       "count  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05   \n",
       "mean   1.589692e-14 -1.646681e-15  3.944007e-14 -1.768761e-14 -1.421181e-14   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -4.923800e+00 -6.231042e+00 -1.396901e+00 -4.507422e+00 -1.212660e+00   \n",
       "25%   -7.222200e-01 -6.744245e-01 -7.776170e-01 -6.856271e-01 -5.680196e-01   \n",
       "50%   -3.082076e-02 -9.074618e-02 -1.833547e-01 -1.871320e-01 -3.182942e-01   \n",
       "75%    6.924892e-01  5.162793e-01  5.547818e-01  6.436931e-01  1.485450e-01   \n",
       "max    6.510879e+00  7.520419e+00  7.726590e+00  1.152750e+01  5.760443e+00   \n",
       "\n",
       "                 20            21            22            23            24  \\\n",
       "count  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05  6.884570e+05   \n",
       "mean   4.660061e-14 -5.213436e-13 -1.205046e-14 -2.197143e-14 -3.190386e-14   \n",
       "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
       "min   -7.298593e+00 -1.561772e+01 -4.557371e+00 -7.979223e+00 -1.266837e+00   \n",
       "25%   -6.669183e-01 -3.647201e-01 -6.957136e-01 -5.647793e-01 -6.792776e-01   \n",
       "50%   -8.177058e-02  1.984675e-01 -1.056716e-01 -2.554492e-02 -3.155505e-01   \n",
       "75%    6.984264e-01  5.739258e-01  6.074958e-01  5.136853e-01  3.279667e-01   \n",
       "max    8.305347e+00  8.085873e-01  4.077391e+00  6.849665e+00  4.636734e+00   \n",
       "\n",
       "                 25  \n",
       "count  6.884570e+05  \n",
       "mean   4.919475e-14  \n",
       "std    1.000001e+00  \n",
       "min   -1.427581e+00  \n",
       "25%   -6.114259e-01  \n",
       "50%   -2.089383e-01  \n",
       "75%    3.947932e-01  \n",
       "max    2.159248e+01  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Brief check - is the mean now 0 and std now 1?\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009529</td>\n",
       "      <td>-1.152743e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.754928e-16</td>\n",
       "      <td>-0.1898</td>\n",
       "      <td>-0.421155</td>\n",
       "      <td>0.06791</td>\n",
       "      <td>-0.610168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.573284e-16</td>\n",
       "      <td>-0.206709</td>\n",
       "      <td>-0.020562</td>\n",
       "      <td>-0.141455</td>\n",
       "      <td>4.595443e-17</td>\n",
       "      <td>-0.21716</td>\n",
       "      <td>-0.669035</td>\n",
       "      <td>-0.417606</td>\n",
       "      <td>1.649476</td>\n",
       "      <td>-0.353297</td>\n",
       "      <td>-0.337951</td>\n",
       "      <td>-0.27682</td>\n",
       "      <td>0.808587</td>\n",
       "      <td>2.045122e-15</td>\n",
       "      <td>-0.227759</td>\n",
       "      <td>-0.483425</td>\n",
       "      <td>-0.644967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0             1    2             3       4         5        6  \\\n",
       "0  0.009529 -1.152743e-15  0.0  2.754928e-16 -0.1898 -0.421155  0.06791   \n",
       "\n",
       "          7    8             9        10        11        12            13  \\\n",
       "0 -0.610168  0.0  5.573284e-16 -0.206709 -0.020562 -0.141455  4.595443e-17   \n",
       "\n",
       "        14        15        16        17        18        19       20  \\\n",
       "0 -0.21716 -0.669035 -0.417606  1.649476 -0.353297 -0.337951 -0.27682   \n",
       "\n",
       "         21            22        23        24        25  \n",
       "0  0.808587  2.045122e-15 -0.227759 -0.483425 -0.644967  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Did we use the mean of the training set for the test as well, to avoid leakage?\n",
    "pd.DataFrame(X_train).mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009529</td>\n",
       "      <td>-1.152743e-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.754928e-16</td>\n",
       "      <td>-0.1898</td>\n",
       "      <td>-0.402343</td>\n",
       "      <td>-0.168148</td>\n",
       "      <td>-0.79118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.573284e-16</td>\n",
       "      <td>0.102432</td>\n",
       "      <td>-0.020562</td>\n",
       "      <td>-0.124057</td>\n",
       "      <td>4.595443e-17</td>\n",
       "      <td>-4.900752e-17</td>\n",
       "      <td>-0.13719</td>\n",
       "      <td>0.749751</td>\n",
       "      <td>-0.471103</td>\n",
       "      <td>-0.187132</td>\n",
       "      <td>3.491676e-16</td>\n",
       "      <td>-0.471869</td>\n",
       "      <td>0.808587</td>\n",
       "      <td>2.045122e-15</td>\n",
       "      <td>-0.227759</td>\n",
       "      <td>-0.735236</td>\n",
       "      <td>-0.343101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0             1    2             3       4         5         6  \\\n",
       "0  0.009529 -1.152743e-15  0.0  2.754928e-16 -0.1898 -0.402343 -0.168148   \n",
       "\n",
       "         7    8             9        10        11        12            13  \\\n",
       "0 -0.79118  0.0  5.573284e-16  0.102432 -0.020562 -0.124057  4.595443e-17   \n",
       "\n",
       "             14       15        16        17        18            19  \\\n",
       "0 -4.900752e-17 -0.13719  0.749751 -0.471103 -0.187132  3.491676e-16   \n",
       "\n",
       "         20        21            22        23        24        25  \n",
       "0 -0.471869  0.808587  2.045122e-15 -0.227759 -0.735236 -0.343101  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Did we use the mean of the training set for the test as well, to avoid leakage?\n",
    "pd.DataFrame(X_test).mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Instance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute standalone sample weights (without class weights)\n",
    "instance_weights = []\n",
    "\n",
    "for dfx in [df_train, df_val, df_test]:\n",
    "    #Dataframe with sample weights, initially contains counts (number of instances) per patient\n",
    "    dfx_weights = dfx\\\n",
    "        .groupby('subject_id')['charttime']\\\n",
    "        .count()\\\n",
    "        .to_frame()\\\n",
    "        .reset_index()\\\n",
    "        .rename(columns={'charttime':'instance_weight'}) #Be sure to pick column without missing values\n",
    "\n",
    "    #Compute weights from the counts based on the number of instances per patient\n",
    "    dfx_weights['instance_weight'] = dfx_weights['instance_weight'].apply(lambda x: 1/x)\n",
    "\n",
    "    #Converting sample weights to the shape that fits X, i.e. row-per-instance\n",
    "    instance_weight = dfx.merge(dfx_weights, on='subject_id', how='left')['instance_weight'].values\n",
    "    \n",
    "    #Store result for use outside this loop\n",
    "    instance_weights.append(instance_weight)\n",
    "    \n",
    "instance_weights_train, instance_weights_val, instance_weights_test = instance_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export data to pickles for easy re-use in other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframes\n",
    "# for dfx, name in zip([df_train, df_val, df_test], ['df_train', 'df_val', 'df_test']):\n",
    "#     dfx.to_hdf(path_or_buf=os.path.join(data_base_path, \"modeling_data/\" + name + \".hdf\"),\n",
    "#                key='Processed_data',\n",
    "#                mode='w',\n",
    "#                complevel=9\n",
    "#             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Processed features & target labels\n",
    "# for X_, y_, X_name, y_name in zip([X_train, X_val, X_test], [y_train, y_val, y_test], ['X_train', 'X_val', 'X_test'], ['y_train', 'y_val', 'y_test']):\n",
    "#     pd.DataFrame(X_).to_hdf(\n",
    "#         path_or_buf=os.path.join(data_base_path, \"modeling_data/\" + X_name + \".hdf\"),\n",
    "#         key='Processed_data',\n",
    "#         mode='w',\n",
    "#         complevel=9\n",
    "#     )\n",
    "    \n",
    "#     pd.DataFrame(y_).to_hdf(\n",
    "#         path_or_buf=os.path.join(data_base_path, \"modeling_data/\" + y_name + \".hdf\"),\n",
    "#         key='Processed_data',\n",
    "#         mode='w',\n",
    "#         complevel=9\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Means & stds for recovering original scale\n",
    "# pd.DataFrame(means).to_hdf(\n",
    "#     path_or_buf=os.path.join(data_base_path, \"modeling_data/\" + 'means' + \".hdf\"),\n",
    "#     key='Processed_data',\n",
    "#     mode='w',\n",
    "#     complevel=9\n",
    "# )\n",
    "\n",
    "# pd.DataFrame(stds).to_hdf(\n",
    "#     path_or_buf=os.path.join(data_base_path, \"modeling_data/\" + 'stds' + \".hdf\"),\n",
    "#     key='Processed_data',\n",
    "#     mode='w',\n",
    "#     complevel=9\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instance weights\n",
    "# for instance_weights, name in zip([instance_weights_train, instance_weights_val, instance_weights_test], ['instance_weights_train', 'instance_weights_val', 'instance_weights_test']):\n",
    "#     pd.DataFrame(instance_weights).to_hdf(\n",
    "#         path_or_buf=os.path.join(data_base_path, \"modeling_data/\" + name + \".hdf\"),\n",
    "#         key='Processed_data',\n",
    "#         mode='w',\n",
    "#         complevel=9\n",
    "#     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
